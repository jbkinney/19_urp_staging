{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Learning-Goals\" data-toc-modified-id=\"Learning-Goals-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Learning Goals</a></span></li><li><span><a href=\"#Searching-for-new-software\" data-toc-modified-id=\"Searching-for-new-software-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Searching for new software</a></span><ul class=\"toc-item\"><li><span><a href=\"#Let's-explore-a-new-package\" data-toc-modified-id=\"Let's-explore-a-new-package-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Let's explore a new package</a></span></li><li><span><a href=\"#Searching-for-functions-within-a-package-we-already-know\" data-toc-modified-id=\"Searching-for-functions-within-a-package-we-already-know-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Searching for functions within a package we already know</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-can-you-do-with-a-groupby-object?\" data-toc-modified-id=\"What-can-you-do-with-a-groupby-object?-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>What can you do with a groupby object?</a></span></li></ul></li></ul></li><li><span><a href=\"#Creating-your-own-functions\" data-toc-modified-id=\"Creating-your-own-functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Creating your own functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Optional-Arguments-and-Keyword-Arguments\" data-toc-modified-id=\"Optional-Arguments-and-Keyword-Arguments-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Optional Arguments and Keyword Arguments</a></span></li><li><span><a href=\"#Loading-in-homemade-scripts\" data-toc-modified-id=\"Loading-in-homemade-scripts-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Loading in homemade scripts</a></span></li><li><span><a href=\"#Creating-your-own-documentation\" data-toc-modified-id=\"Creating-your-own-documentation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Creating your own documentation</a></span></li><li><span><a href=\"#Review-Questions-and-Exercise\" data-toc-modified-id=\"Review-Questions-and-Exercise-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Review Questions and Exercise</a></span></li></ul></li><li><span><a href=\"#Integrated-Analysis-using-Objects\" data-toc-modified-id=\"Integrated-Analysis-using-Objects-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Integrated Analysis using Objects</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exercise\" data-toc-modified-id=\"Exercise-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Exercise</a></span></li></ul></li><li><span><a href=\"#Extra-Resources\" data-toc-modified-id=\"Extra-Resources-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Extra Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Conda-python-environments\" data-toc-modified-id=\"Conda-python-environments-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Conda python environments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Installing-packages\" data-toc-modified-id=\"Installing-packages-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Installing packages</a></span></li></ul></li><li><span><a href=\"#Packages-can-be-incompatible-with-each-other\" data-toc-modified-id=\"Packages-can-be-incompatible-with-each-other-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Packages can be incompatible with each other</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-06-12T20:27:05.380Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import scipy as sp \n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rc(\"axes.spines\", top=False, right=False)\n",
    "sns.set(style='white', font_scale=1.25)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Comfortable searching for new software\n",
    "2. Learn how to install software\n",
    "3. Get comfortable writing documentation for yourself\n",
    "4. Get comfortable reading other people's documentation and using their software\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    ">Software documentation is written text or illustration that accompanies computer software or is embedded in the source code. The documentation either explains how the software operates or how to use it, and may mean different things to people in different roles. - [Wikipedia](https://en.wikipedia.org/wiki/Software_documentation)\n",
    "\n",
    "It is impossible to program anything without reading documentation. While it may be nice to code everything yourself, for most problems it will be faster to use a package with a function that someone else wrote. \n",
    "\n",
    "As of June 1st 2019 there are 182,064 projects on PyPi, the main python repository, and there are way more that are just hosted on github directly. Basically if you want to do something in python that someone else has already done, there's probably a package for it. \n",
    "\n",
    "However, you should be careful with which packages you install, and just because it exists now, doesn't mean it will work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for new software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Let's explore a new package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this example we will be using survival analysis as an example for finding a package. \n",
    "\n",
    "In short, survival analysis we are trying to see how the probability of surviving changes over time and also what features correlate with survival. The first analysis is known as Kaplan-Meir Analysis and the second is known as CoxProportional Hazards  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to find a package. So lets [google python survival analysis](http://lmgtfy.com/?q=python+survival+analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:10:59.520808Z",
     "start_time": "2019-06-11T15:10:57.961737Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:10:59.558022Z",
     "start_time": "2019-06-11T15:10:59.524677Z"
    }
   },
   "outputs": [],
   "source": [
    "from lifelines.datasets import load_waltons\n",
    "df = load_waltons() # returns a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">\"Genotypes and number of days survived in Drosophila. Since we work with flies, we don’t need to worry about left-censoring. We know the birth date of all flies. We do have issues with accidentally killing some or if some escape. These would be right-censored as we do not actually observe their death due to “natural” causes.:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:10:59.563822Z",
     "start_time": "2019-06-11T15:10:59.560357Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "T = df['T']\n",
    "E = df['E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:10:59.569665Z",
     "start_time": "2019-06-11T15:10:59.566801Z"
    }
   },
   "outputs": [],
   "source": [
    "from lifelines import KaplanMeierFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:10:59.599163Z",
     "start_time": "2019-06-11T15:10:59.572346Z"
    }
   },
   "outputs": [],
   "source": [
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(T,E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:10:59.858021Z",
     "start_time": "2019-06-11T15:10:59.601453Z"
    }
   },
   "outputs": [],
   "source": [
    "kmf.survival_function_\n",
    "kmf.cumulative_density_\n",
    "kmf.median_\n",
    "\n",
    "kmf.plot_survival_function()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.025903Z",
     "start_time": "2019-06-11T15:10:59.860139Z"
    }
   },
   "outputs": [],
   "source": [
    "kmf.plot_cumulative_density()\n",
    "sns.despine()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.246406Z",
     "start_time": "2019-06-11T15:11:00.028278Z"
    }
   },
   "outputs": [],
   "source": [
    "groups = df['group']\n",
    "ix = (groups == 'miR-137')\n",
    "\n",
    "kmf.fit(T[~ix], E[~ix], label='control')\n",
    "ax = kmf.plot()\n",
    "\n",
    "kmf.fit(T[ix], E[ix], label='miR-137')\n",
    "ax = kmf.plot(ax=ax)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching for functions within a package we already know\n",
    "\n",
    "What if I don't like the way that the tutorial is splitting up the groups because you have to manually do this based on typing (hardcoding) the array to slice the dataframe. \n",
    "\n",
    "Would you say that it is reasonable that there should a way to split up a dataframe based on the values of a column, maybe a **groupby** function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.251245Z",
     "start_time": "2019-06-11T15:11:00.248494Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_df = df.groupby('group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What can you do with a groupby object? \n",
    "\n",
    "Lots of Stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.263358Z",
     "start_time": "2019-06-11T15:11:00.252932Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.273704Z",
     "start_time": "2019-06-11T15:11:00.265346Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.288223Z",
     "start_time": "2019-06-11T15:11:00.275663Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Geometric Mean\n",
    "grouped_df.apply(lambda x: np.mean(np.log1p(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.306292Z",
     "start_time": "2019-06-11T15:11:00.290151Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit_line(x):\n",
    "    return pd.Series(\n",
    "        stats.linregress(x),\n",
    "        index=['slope', 'intercept', 'r-value', 'p-value', 'stderr'])\n",
    "\n",
    "grouped_df.apply(fit_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All of these methods output a dataframe though, what if I want to the output to be a plot?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.314819Z",
     "start_time": "2019-06-11T15:11:00.309643Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_df.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.321249Z",
     "start_time": "2019-06-11T15:11:00.316933Z"
    }
   },
   "outputs": [],
   "source": [
    "for name, index in grouped_df.groups.items():\n",
    "    print(name)\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.327063Z",
     "start_time": "2019-06-11T15:11:00.323124Z"
    }
   },
   "outputs": [],
   "source": [
    "type(grouped_df.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.520412Z",
     "start_time": "2019-06-11T15:11:00.328958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for name, index in grouped_df.groups.items():\n",
    "    kmf.fit(T[index], E[index], label=name)\n",
    "    kmf.plot(ax=ax)\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your own functions\n",
    "\n",
    "Rarely in programming are you just going to write code that will be only used once. \n",
    "\n",
    "\n",
    "<img src=\"https://media.licdn.com/dms/image/C4D12AQGh9akjkrIkeg/article-cover_image-shrink_600_2000/0?e=1561593600&v=beta&t=YlHiNmLbh1M3BeMwZH0bmsnZZAIaeZw0N5_7e5u63Ho\" />\n",
    "\n",
    "Software developers often use the phrase **DRY** or Don't Repeat Yourself.\n",
    "\n",
    "The way we accomplish this is by writing generalized functions that can repeat a task for you multiple times.\n",
    "\n",
    "Let's write a function for creating a grouped Kaplan Meir plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.527606Z",
     "start_time": "2019-06-11T15:11:00.522536Z"
    }
   },
   "outputs": [],
   "source": [
    "def survival_plot(df, grouping_col, time_col, event_col):\n",
    "    grouped_df = df.groupby(grouping_col)\n",
    "    fig, ax = plt.subplots()\n",
    "    for name, index in grouped_df.groups.items():\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(df.loc[index, time_col], df.loc[index, event_col], label=name)\n",
    "        kmf.plot(ax=ax)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.809897Z",
     "start_time": "2019-06-11T15:11:00.529161Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "survival_plot(df, 'group', 'T','E')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.815429Z",
     "start_time": "2019-06-11T15:11:00.812687Z"
    }
   },
   "outputs": [],
   "source": [
    "from lifelines.datasets import load_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:00.842960Z",
     "start_time": "2019-06-11T15:11:00.818013Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = load_dd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets test our new function on this other dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:14:07.637567Z",
     "start_time": "2019-06-12T15:14:06.881885Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for c in df2:\n",
    "    if c in ['observed', 'duration']:\n",
    "        continue\n",
    "    n_cat = np.unique(df2[c].values).shape[0]\n",
    "    if n_cat > 10:\n",
    "        continue\n",
    "    print(c, n_cat)\n",
    "\n",
    "    survival_plot(df2, c, 'duration', 'observed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating general functions around a common analysis that you are going to do will save you time and energy. It will also help make all your result plots standardized, which your mentors and PIs will thank you. \n",
    "\n",
    "When you are going to do something a couple of times within a single notebook it is perfectly fine to leave the function in the notebook, however if you think that you will be using this in many notebooks it can be convenient to put that function in a separate script and import the function into each notebook you will be using. (This takes a lot of forethought, and tbh I am not very good at this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional Arguments and Keyword Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:16:48.452536Z",
     "start_time": "2019-06-12T15:16:48.424135Z"
    }
   },
   "outputs": [],
   "source": [
    "def survival_plot_2(df, grouping_col, time_col, event_col,title=None):\n",
    "    grouped_df = df.groupby(grouping_col)\n",
    "    fig, ax = plt.subplots()\n",
    "    for name, index in grouped_df.groups.items():\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(df.loc[index, time_col], df.loc[index, event_col], label=name)\n",
    "        kmf.plot(ax=ax)\n",
    "    if title is not None:\n",
    "        ax.set(title=title)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:17:39.546409Z",
     "start_time": "2019-06-12T15:17:39.220733Z"
    }
   },
   "outputs": [],
   "source": [
    "survival_plot_2(df2, 'regime', 'duration', 'observed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:17:29.145792Z",
     "start_time": "2019-06-12T15:17:28.817509Z"
    }
   },
   "outputs": [],
   "source": [
    "survival_plot_2(df2, 'regime', 'duration', 'observed',title='regime')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional Arguments are a great way to give flexibility to our analysis and plots. Plotting functions tend to have a lot of them, while analysis ones may have fewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you write a function that calls another function with lots of arguments, and you don't want to rewrite all those arguments again, so you can include a `**kwargs` as the last argument in the function, then in the subfunction call you pass kwargs.\n",
    "\n",
    "A good example of this is clustermap and heatmap in seaborn\n",
    "\n",
    "In the documentation for clutsermap it says:\n",
    "\n",
    ">    kwargs : other keyword arguments\n",
    "        All other keyword arguments are passed to `sns.heatmap`\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:35:50.275476Z",
     "start_time": "2019-06-12T15:35:49.850604Z"
    }
   },
   "outputs": [],
   "source": [
    "expression_demo = pd.read_csv('../data/example_expression.csv', index_col=0)\n",
    "corr_network = pd.DataFrame(\n",
    "    np.corrcoef(expression_demo.values.T),\n",
    "    index=expression_demo.columns,\n",
    "    columns=expression_demo.columns)\n",
    "corr_network.index.name = 'Genes'\n",
    "corr_network.columns.name = 'Genes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:36:02.273652Z",
     "start_time": "2019-06-12T15:36:01.219423Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.clustermap(corr_network, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T15:36:34.883047Z",
     "start_time": "2019-06-12T15:36:34.855758Z"
    }
   },
   "source": [
    "Using `?sns.heatmap` and `?sns.colormap` you will see that only heatmap has a `cmap` argument. When you are searching documentation for an argument that you think should be there and it isn't go check where the kwargs are passed and then you can check that function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in homemade scripts\n",
    "\n",
    "As you can see by the folder structure, I store my scripts in a separate folder and I need to tell python where it is.\n",
    "\n",
    "In computers this is called the path, the path always includes the directory (fancy CS word for folder) that you are running your notebook in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:01.776373Z",
     "start_time": "2019-06-11T15:11:01.647600Z"
    }
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using terminal you can also see the entire path of the computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:01.906775Z",
     "start_time": "2019-06-11T15:11:01.779554Z"
    }
   },
   "outputs": [],
   "source": [
    "!echo $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you will notice that ../scripts/ is not in the path. So we need to add to it using the sys module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:01.912456Z",
     "start_time": "2019-06-11T15:11:01.909732Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:01.916955Z",
     "start_time": "2019-06-11T15:11:01.914249Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../scripts/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can see that at the end of the path is ../scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:02.073961Z",
     "start_time": "2019-06-11T15:11:02.067241Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we import it we need to add something to our notebooks..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:02.984442Z",
     "start_time": "2019-06-11T15:11:02.939786Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically that will allow us to modify the script files and then it will update the functions we are using here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:03.020741Z",
     "start_time": "2019-06-11T15:11:02.987661Z"
    }
   },
   "outputs": [],
   "source": [
    "import survival_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can see that you can now import survival functions, and just like with a normal module you can do all sorts of ways of importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:03.418679Z",
     "start_time": "2019-06-11T15:11:03.389550Z"
    }
   },
   "outputs": [],
   "source": [
    "from survival_functions import survival_plot\n",
    "import survival_functions as sf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can even test it to show that it works still"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:11:03.650640Z",
     "start_time": "2019-06-11T15:11:03.421411Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sf.survival_plot(df, 'group','T','E')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Creating your own documentation\n",
    "\n",
    "Now we know this function works and we can use it form the script. But how will I know how it works 2 months form now when I am using again?\n",
    "\n",
    "Understanding how to create your own documentation will also help you with reading documentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:21:00.113898Z",
     "start_time": "2019-06-11T15:21:00.066525Z"
    }
   },
   "outputs": [],
   "source": [
    "?survival_functions.survival_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ? shows all the info you have about the information about the function or even object that you are interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:23:49.480216Z",
     "start_time": "2019-06-11T15:23:49.453373Z"
    }
   },
   "outputs": [],
   "source": [
    "?grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use these all the time because I can never remember the order of arguments. They also can tell you what the function does. An they are super easy to create. You just need to put any text you want in the **docstring** `\"\"\" \"\"\"` below the `def func():` line of the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:27:37.107156Z",
     "start_time": "2019-06-11T15:27:37.081377Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_something(x):\n",
    "    \"\"\"Adds 1 to the value x\"\"\"\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:27:37.396975Z",
     "start_time": "2019-06-11T15:27:37.370979Z"
    }
   },
   "outputs": [],
   "source": [
    "do_something(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is really important is that you can give info about each argument so that you know what to put in the function. One important thing to include is the type of the data.\n",
    "\n",
    "Here's the *official* style format for python docstrings https://www.python.org/dev/peps/pep-0257/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:33:13.828150Z",
     "start_time": "2019-06-11T15:33:13.800368Z"
    }
   },
   "outputs": [],
   "source": [
    "def survival_plot_w_doc(df, grouping_col, time_col, event_col):\n",
    "    \"\"\"\n",
    "    Kaplan Meir Plot of data grouped by a column\n",
    "    \n",
    "    \n",
    "    df (pd.DataFrame) : Dataframe with all columns needed for grouping survival analysis\n",
    "    grouping_col (str) : Name of column for grouping by\n",
    "    time_col (str): Name of column for survival time, must be a numeric column\n",
    "    event_col (str): Name of col of boolean flag for whether survival event occured\n",
    "    \n",
    "    returns: None\n",
    "    outputs: plot\n",
    "    \"\"\"\n",
    "    grouped_df = df.groupby(grouping_col)\n",
    "    fig, ax = plt.subplots()\n",
    "    for name, index in grouped_df.groups.items():\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(df.loc[index, time_col], df.loc[index, event_col], label=name)\n",
    "        kmf.plot(ax=ax)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:33:10.679770Z",
     "start_time": "2019-06-11T15:33:10.647681Z"
    }
   },
   "source": [
    "That can be kind of time consuming, but what can be faster is just giving type hints, you just put a colon then then data type that the argument is supposed to be. Usually when you're trying to learn how to use a function knowing the datatype that you need to input is one of the first things you need to check\n",
    "\n",
    "**The program does not check that the type hints match the type of what you pass the function, they are purely for documentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:57:49.105113Z",
     "start_time": "2019-06-12T18:57:49.075697Z"
    }
   },
   "outputs": [],
   "source": [
    "def survival_plot_w_type_hints(df : pd.DataFrame, grouping_col : str, time_col: str, event_col : str):\n",
    "    grouped_df = df.groupby(grouping_col)\n",
    "    fig, ax = plt.subplots()\n",
    "    for name, index in grouped_df.groups.items():\n",
    "        kmf = KaplanMeierFitter()\n",
    "        kmf.fit(df.loc[index, time_col], df.loc[index, event_col], label=name)\n",
    "        kmf.plot(ax=ax)\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T18:57:49.370577Z",
     "start_time": "2019-06-12T18:57:49.342824Z"
    }
   },
   "outputs": [],
   "source": [
    "?survival_plot_w_type_hints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other important thing is whether or not the function returns something, or does it inplace. A lot of functions also have options for it. \n",
    "\n",
    "Check out the numpy nan_to_num function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:02:51.768889Z",
     "start_time": "2019-06-11T16:02:51.738739Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.arange(100, dtype=float)\n",
    "a[np.random.randint(0,99,10)] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:02:52.096392Z",
     "start_time": "2019-06-11T16:02:52.063124Z"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:02:52.582001Z",
     "start_time": "2019-06-11T16:02:52.549705Z"
    }
   },
   "outputs": [],
   "source": [
    "np.nan_to_num(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:02:54.792704Z",
     "start_time": "2019-06-11T16:02:54.766094Z"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:03:09.169691Z",
     "start_time": "2019-06-11T16:03:09.142725Z"
    }
   },
   "outputs": [],
   "source": [
    "np.nan_to_num(a,copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:03:11.357778Z",
     "start_time": "2019-06-11T16:03:11.325482Z"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how with `copy=False` the Nans are saved as 0s, while without that they are still nans, regardless of whether or not you are copying this function does output the result, other functions may output results if you are not doing the function inplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you go on websites like readthedocs and other documentation sites they are literally pretty ways to display docstrings. You can even test this out yourself if you go to the webpage for [numpy's zeros function](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T15:58:36.004758Z",
     "start_time": "2019-06-11T15:58:35.974850Z"
    }
   },
   "outputs": [],
   "source": [
    "?np.zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Questions and Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the most important things to look at when trying to learn how to use function in a package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer Here**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Given the two lists of letters below go create a venn diagram of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:11:49.660525Z",
     "start_time": "2019-06-11T16:11:49.634068Z"
    }
   },
   "outputs": [],
   "source": [
    "letters = 'abcdefghijklmnopqrstuvwxyz'\n",
    "list1 = set(np.array([letters[i] for i in np.random.randint(0,26,10)]))\n",
    "list2 = set(np.array([letters[i] for i in np.random.randint(0,26,10)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:12:41.099381Z",
     "start_time": "2019-06-11T16:12:37.607081Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:13:19.974656Z",
     "start_time": "2019-06-11T16:13:19.937860Z"
    }
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T16:14:20.572506Z",
     "start_time": "2019-06-11T16:14:20.501553Z"
    }
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Take our survival function and make it optional to change the x axis label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Analysis using Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[scanpy](https://scanpy-tutorials.readthedocs.io/en/latest/index.html) is a fully integrated package for analysis of scRNAseq data. You can start with data that is unprocessed and go all the way to publication ready results within it. The documentation can be overwhelming at times and it has it's own grammar that you need to learn. But this can be quite representative of what a lot of programming language based analysis look like. \n",
    "\n",
    "While software with graphical user interfaces (GUIs) may be easier to use at first, being able to work with a software package using programming gives you way more flexibility and control over your analysis, even though it may be harder at first.\n",
    "\n",
    "For this exercise we will be using the same data, but all of it, from the differential expression exercise from my other lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T17:43:06.114006Z",
     "start_time": "2019-06-11T17:43:06.089382Z"
    }
   },
   "outputs": [],
   "source": [
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T17:48:52.655525Z",
     "start_time": "2019-06-11T17:48:47.289615Z"
    }
   },
   "outputs": [],
   "source": [
    "zeng_data = sc.read_h5ad('../data/zeng_smart_nuc_object.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T17:52:59.394656Z",
     "start_time": "2019-06-11T17:52:59.366740Z"
    }
   },
   "outputs": [],
   "source": [
    "zeng_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with scanpy the data needs to be stored in what is known as an anndata object. These objects have lots of attributes, and even some attributes have attributes within that. You can access all of the attributes using the name of the object then a dot like: `zeng_data.` \n",
    "\n",
    "Anndata stands for annotated data, putting the name of an object on it's own in a cell and running it will show it's attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T17:49:07.329470Z",
     "start_time": "2019-06-11T17:49:07.302895Z"
    }
   },
   "outputs": [],
   "source": [
    "andata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://falexwolf.de/img/scanpy/anndata.svg\" />\n",
    "\n",
    "The figure above outlines how this works, the most important thing to remember is that:\n",
    "\n",
    "**Var = Genes** \n",
    "\n",
    "**Obs = Samples**\n",
    "\n",
    "Each of `.var` and `.obs` have the same number of entries as the number of genes and samples, respectively.\n",
    "\n",
    "Stuff that doesn't fit into either of those list go into the `.uns` section, which is unstructured data\n",
    "\n",
    "As you run functions you will see that stuff will get added to the `.var` and `.obs` attributes as necessary\n",
    "\n",
    "The actual data is stored as `.X` as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T17:53:05.063857Z",
     "start_time": "2019-06-11T17:53:05.027424Z"
    }
   },
   "outputs": [],
   "source": [
    "zeng_data.obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T17:53:10.945810Z",
     "start_time": "2019-06-11T17:53:10.915263Z"
    }
   },
   "outputs": [],
   "source": [
    "zeng_data.var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the both the `.obs` and `.var` attributes are both pandas dataframes, we can even treat them as such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:03:03.835451Z",
     "start_time": "2019-06-11T18:03:03.615406Z"
    }
   },
   "outputs": [],
   "source": [
    "zeng_data.var['sum_counts'] = zeng_data.X.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:03:08.628740Z",
     "start_time": "2019-06-11T18:03:08.598446Z"
    }
   },
   "outputs": [],
   "source": [
    "zeng_data.var.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also subset the entire object like an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:03:35.405533Z",
     "start_time": "2019-06-11T18:03:35.373593Z"
    }
   },
   "outputs": [],
   "source": [
    "#This selects the first 10 genes \n",
    "zeng_data[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:04:12.264281Z",
     "start_time": "2019-06-11T18:04:12.231315Z"
    }
   },
   "outputs": [],
   "source": [
    "#You can also pass list of genes or arrays to subset\n",
    "zeng_data[:,['Cacna1a','Ogt']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might imagine, the preprocessing steps can be quite standard, so we are going to go over those together, then I'm gonna let you explore the other tools to see what stuff you can do. All of the preprocessing can be done using the `sc.pp.` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:11:14.154540Z",
     "start_time": "2019-06-11T18:11:12.459480Z"
    }
   },
   "outputs": [],
   "source": [
    "#This converts the units of the data from counts -> CPM\n",
    "sc.pp.normalize_total(zeng_data,target_sum=1e6)\n",
    "\n",
    "#This removes genes with no counts\n",
    "sc.pp.filter_genes(zeng_data, min_cells=1)\n",
    "\n",
    "#This converts CPM -> log(CPM)\n",
    "sc.pp.log1p(zeng_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:13:53.398831Z",
     "start_time": "2019-06-11T18:13:51.869475Z"
    }
   },
   "outputs": [],
   "source": [
    "#This identifies significantly informative features in the data\n",
    "sc.pp.highly_variable_genes(zeng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:15:56.444503Z",
     "start_time": "2019-06-11T18:15:54.222877Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pl.highly_variable_genes(zeng_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sc.pp` library contains only functions that alter the anndata object, but many of them have companion functions for plotting in the `sc.pl` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:14:10.831298Z",
     "start_time": "2019-06-11T18:14:06.266597Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.pca(zeng_data, use_highly_variable=False)\n",
    "sc.pl.pca(zeng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:14:13.981565Z",
     "start_time": "2019-06-11T18:14:12.457159Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.pca(zeng_data, use_highly_variable=True)\n",
    "sc.pl.pca(zeng_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is a dimensional reduction method. It maximizes the variance over subsequent latent spaces, As you can see whether or not you use only highly variable genes greatly affects the output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:14:33.299256Z",
     "start_time": "2019-06-11T18:14:33.098914Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pl.pca_variance_ratio(zeng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:19:56.843959Z",
     "start_time": "2019-06-11T18:19:42.235367Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.pp.neighbors(zeng_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've done a bunch of stuff to our data, lets check back on our object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T18:14:37.952360Z",
     "start_time": "2019-06-11T18:14:37.924890Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "zeng_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a lot of stuff was added, some of which we haven't discussed. Can anyone figure out what `.obsm` and `.varm` are? \n",
    "\n",
    "At this point we've covered most of the preprocessing module, and now can mess around with the tl (tools) and pl (plotting) modules. \n",
    "\n",
    "For example lets try lieden clustering then plot it in pca space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T19:57:15.653337Z",
     "start_time": "2019-06-11T19:57:13.800651Z"
    }
   },
   "outputs": [],
   "source": [
    "sc.tl.leiden(zeng_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T19:57:08.324373Z",
     "start_time": "2019-06-11T19:54:50.025534Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install leidenalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:33:55.987781Z",
     "start_time": "2019-06-11T20:33:55.710046Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sc.pl.pca(zeng_data, color='leiden')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Write a function that takes in a file name and then does all the preprocessing, including plotting, for a single cell dataset. Have it return the anndata object and include what you think is necessary documentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run louvain clustering and plot it on a UMAP embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:40:44.926047Z",
     "start_time": "2019-06-11T20:38:33.855710Z"
    }
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:41:09.702665Z",
     "start_time": "2019-06-11T20:41:08.926059Z"
    }
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now run diffusion map and plot it and color by broad_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-11T20:44:45.900342Z",
     "start_time": "2019-06-11T20:44:45.491164Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Figure out which cluster(s) in lieden and louvain correspond to Glia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-12T14:50:19.672715Z",
     "start_time": "2019-06-12T14:50:19.645069Z"
    }
   },
   "outputs": [],
   "source": [
    "##TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conda python environments\n",
    "\n",
    "In google colab we have been using `pip` to install our packages. Pip is the great but has limited uses and doesn't offer some of the safety features that using the anaconda version of python. \n",
    "\n",
    "To use conda I would recomend installing [miniconda](https://docs.conda.io/en/latest/miniconda.html) (Unless your computer is >10 years old you should use the 64bit version)\n",
    "\n",
    "Here is a [cheat sheet](https://docs.conda.io/projects/conda/en/latest/_downloads/1f5ecf5a87b1c1a8aaf5a7ab8a7a0ff7/conda-cheatsheet.pdf) for all of the things that you can do with conda.\n",
    "\n",
    "#### Installing packages\n",
    "When I am installing a new package I do this:\n",
    "\n",
    "1. Start out by google \"conda PACKAGE NAME\"  (lets use matplotlib-venn as an example)\n",
    "2. Look for the [link](https://anaconda.org/conda-forge/matplotlib-venn) that has anaconda.org in the url \n",
    "3. Copy the first line under the \"To install this\" section\n",
    "4. Paste into terminal and run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages can be incompatible with each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my previous lecture I taught about plotting in python using Matplotlib and Seaborn. However, anyone familiar with R likely has heard of ggplot. ggplot is an extremely powerful package for plotting, it uses a vastly different grammar than matplotlib. Some people really love it though, so someone decided to \"port\" it over to python. \n",
    "\n",
    "Using conda if you try installing it using this line in terminal: `conda install -c conda-forge ggplot` , conda will ask you this before you decide to install it. \n",
    "\n",
    "<img src=\"../figures/ggplot_install.png\" />\n",
    "\n",
    "When you see this output, don't immediately say yes. You should take a look at the output to see what will happen. There can be up to 2 important sections  **UPDATED**, and **DOWNGRADED** that are worth your attention. You see if there are any packages that are making large jumps in upgrading or downgrading. It is normal to see a lot of packages that you have never heard of, but you should look for red flags, like changing the version of your most used packages and also of python. In this output downloading ggplot would turn my python version from 3.7.2 $->$ 3.6.8\n",
    "\n",
    "Between the fact that I am more experienced with seaborn and matplotlib and because ggplot will vastly change my python environment I will not use it. \n",
    "\n",
    "If really want/need a package that is incompatible then you can create a new environment and install the package in there. Here is a tutorial on that : https://docs.conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "368px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
